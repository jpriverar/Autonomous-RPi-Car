{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5081fb87-89ba-4e8d-98aa-0820d0d32039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import struct \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccae285d-a206-4c6e-a950-14b4f768d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 341056)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               43655296  \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,674,817\n",
      "Trainable params: 43,674,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating our traffic light model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "desired_size = 300\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, desired_size, desired_size)\n",
    "else:\n",
    "    input_shape = (desired_size, desired_size, 3)\n",
    "\n",
    "stopLight_model = Sequential()\n",
    "\n",
    "stopLight_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
    "stopLight_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "stopLight_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "stopLight_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "stopLight_model.add(Flatten())\n",
    "\n",
    "stopLight_model.add(Dense(128))\n",
    "stopLight_model.add(Activation('relu'))\n",
    "stopLight_model.add(Dropout(0.5))\n",
    "\n",
    "stopLight_model.add(Dense(1))\n",
    "stopLight_model.add(Activation('sigmoid'))\n",
    "\n",
    "stopLight_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "stopLight_model.summary()\n",
    "\n",
    "stopLight_model.load_weights('stopLightCNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e56d6d-6f49-45a2-819f-0d844505cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 341056)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               43655296  \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,674,817\n",
      "Trainable params: 43,674,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating our car model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "desired_size = 300\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, desired_size, desired_size)\n",
    "else:\n",
    "    input_shape = (desired_size, desired_size, 3)\n",
    "\n",
    "car_model = Sequential()\n",
    "\n",
    "car_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
    "car_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "car_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "car_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "car_model.add(Flatten())\n",
    "\n",
    "car_model.add(Dense(128))\n",
    "car_model.add(Activation('relu'))\n",
    "car_model.add(Dropout(0.5))\n",
    "\n",
    "car_model.add(Dense(1))\n",
    "car_model.add(Activation('sigmoid'))\n",
    "\n",
    "car_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "car_model.summary()\n",
    "\n",
    "car_model.load_weights('carCNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70fee43-091c-4675-bbee-1559ff383e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 341056)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               43655296  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,674,817\n",
      "Trainable params: 43,674,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating our people model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "desired_size = 300\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, desired_size, desired_size)\n",
    "else:\n",
    "    input_shape = (desired_size, desired_size, 3)\n",
    "\n",
    "people_model = Sequential()\n",
    "\n",
    "people_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
    "people_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "people_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "people_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "people_model.add(Flatten())\n",
    "\n",
    "people_model.add(Dense(128))\n",
    "people_model.add(Activation('relu'))\n",
    "people_model.add(Dropout(0.5))\n",
    "\n",
    "people_model.add(Dense(1))\n",
    "people_model.add(Activation('sigmoid'))\n",
    "\n",
    "people_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "people_model.summary()\n",
    "\n",
    "people_model.load_weights('peopleCNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51aad669-0381-4cad-ac68-aa1cb7c12aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 341056)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               43655296  \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,675,204\n",
      "Trainable params: 43,675,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating our traffic light color model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "desired_size = 300\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, desired_size, desired_size)\n",
    "else:\n",
    "    input_shape = (desired_size, desired_size, 3)\n",
    "\n",
    "color_model = Sequential()\n",
    "\n",
    "color_model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n",
    "color_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "color_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "color_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "color_model.add(Flatten())\n",
    "\n",
    "color_model.add(Dense(128))\n",
    "color_model.add(Activation('relu'))\n",
    "color_model.add(Dropout(0.5))\n",
    "\n",
    "color_model.add(Dense(4))\n",
    "color_model.add(Activation('softmax'))\n",
    "\n",
    "color_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "color_model.summary()\n",
    "\n",
    "color_model.load_weights('stopLightColorCNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b090a7b5-5c91-4be4-91c8-325edb686061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socket created\n",
      "Socket bind complete\n",
      "Socket now listening\n",
      "payload_size: 4\n"
     ]
    }
   ],
   "source": [
    "# Predicting frames from video streaming\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "HOST=''\n",
    "PORT=8485\n",
    "\n",
    "s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "print('Socket created')\n",
    "\n",
    "s.bind((HOST,PORT))\n",
    "print('Socket bind complete')\n",
    "s.listen(10)\n",
    "print('Socket now listening')\n",
    "\n",
    "conn,addr=s.accept()\n",
    "\n",
    "data = b\"\"\n",
    "payload_size = struct.calcsize(\">L\")\n",
    "print(\"payload_size: {}\".format(payload_size))\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        while len(data) < payload_size:\n",
    "            #print(\"Recv: {}\".format(len(data)))\n",
    "            data += conn.recv(4096)\n",
    "\n",
    "        #print(\"Done Recv: {}\".format(len(data)))\n",
    "        packed_msg_size = data[:payload_size]\n",
    "        data = data[payload_size:]\n",
    "        msg_size = struct.unpack(\">L\", packed_msg_size)[0]\n",
    "        #print(\"msg_size: {}\".format(msg_size))\n",
    "        while len(data) < msg_size:\n",
    "            data += conn.recv(4096)\n",
    "        frame_data = data[:msg_size]\n",
    "        data = data[msg_size:]\n",
    "\n",
    "        frame=pickle.loads(frame_data, fix_imports=True, encoding=\"bytes\")\n",
    "        frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q') or key == 27:\n",
    "            break\n",
    "            \n",
    "        # Predicting frame\n",
    "        img = image.img_to_array(frame)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img/255\n",
    "        \n",
    "        #stopLight_prob = stopLight_model.predict(img)\n",
    "        car_prob = car_model.predict(img)\n",
    "        #people_prob = people_model.predict(img)\n",
    "        \n",
    "        #if stopLight_prob > 0.5:\n",
    "        #    traffic_light = True\n",
    "            #traffic_light = np.argmax(color_model.predict(img)) \n",
    "        #else: traffic_light = False\n",
    "        \n",
    "        car = True if car_prob > 0.5 else False\n",
    "        #people = True if people_prob > 0.5 else False\n",
    "        \n",
    "        # Writing the probability in the frame\n",
    "        cv2.putText(img=frame, text=f\"traffic light: {traffic_light}\", org=(10,50), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(img=frame, text=f\"car: {car}\", org=(10,100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(img=frame, text=f\"people: {people}\", org=(10,150), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    s.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    cv2.destroyAllWindows()\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d7490-bf72-4ff0-900d-1ed9acde15bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
